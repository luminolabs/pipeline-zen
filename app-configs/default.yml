# Local development environment
local_env_name: local
secrets_dir: .secrets

# Workflows
send_to_gcs: true
send_to_bq: true  # enable/disable BigQuery
send_to_pubsub: true  # enable/disable PubSub

# Environment management
delete_results: false  # Set to true to delete results after uploading

# Logging
log_level: INFO
log_stdout: false  # In dev and prod we only want to log to files, to avoid generating duplicate logs

# Paths
root_path: .
cache_dir: .cache
work_dir: .results
job_configs_path: job-configs
finished_file: .finished
started_file: .started
job_meta_file: job-meta.json

# Celery
celery_broker_url: memory://localhost/

# GCP
gcp_project: neat-airport-407301
bq_dataset: pipeline_zen
heartbeat_topic: pipeline-zen-jobs-heartbeats
jobs_meta_topic: pipeline-zen-jobs-meta

# Hugging Face
huggingface_token:  # Set this in your .env file: `PZ_HUGGINGFACE_TOKEN=.....`

# Customer API
customer_api_enabled: true  # Setting to false will disable Customer API calls
customer_api_url:  # This is set in each environment's env files
customer_api_key:  # Set this in your .env file: `PZ_CUSTOMER_API_KEY=.....`
customer_api_credits_deduct_endpoint: /billing/credits-deduct

# Set to true to mock that the user has enough credits
# to run a job and avoid making the API call (useful for local testing)
mock_user_has_enough_credits: false